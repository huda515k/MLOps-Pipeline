version: '3.8'

services:
  # Apache Airflow
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow.optimized
    container_name: airflow-webserver
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKEND=airflow.api.auth.backend.basic_auth
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      - DAGSHUB_USERNAME=${DAGSHUB_USERNAME:-}
      - DAGSHUB_REPO=${DAGSHUB_REPO:-}
      - DAGSHUB_TOKEN=${DAGSHUB_TOKEN:-}
      - MLFLOW_TRACKING_USERNAME=${DAGSHUB_USERNAME:-}
      - MLFLOW_TRACKING_PASSWORD=${DAGSHUB_TOKEN:-}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - airflow-logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: webserver
    depends_on:
      - postgres
      - airflow-init
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow.optimized
    container_name: airflow-scheduler
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      - DAGSHUB_USERNAME=${DAGSHUB_USERNAME:-}
      - DAGSHUB_REPO=${DAGSHUB_REPO:-}
      - DAGSHUB_TOKEN=${DAGSHUB_TOKEN:-}
      - MLFLOW_TRACKING_USERNAME=${DAGSHUB_USERNAME:-}
      - MLFLOW_TRACKING_PASSWORD=${DAGSHUB_TOKEN:-}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - airflow-logs:/opt/airflow/logs
      - mlflow-data:/mlflow:rw
    command: scheduler
    depends_on:
      - postgres
      - airflow-init

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow.optimized
    container_name: airflow-init
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=''
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW_UID=50000
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
    entrypoint: /bin/bash
    command:
      - -c
      - |
        echo "Waiting for postgres..."
        sleep 5
        echo "Initializing Airflow database..."
        airflow db init
        echo "Creating admin user..."
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || echo "User may already exist"
        echo "Airflow initialization complete!"
    depends_on:
      postgres:
        condition: service_healthy

  # FastAPI Prediction Service
  fastapi-service:
    build:
      context: .
      dockerfile: docker/Dockerfile.fastapi.optimized
    container_name: fastapi-service
    env_file:
      - .env
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MODEL_NAME=weather_forecast_model
    volumes:
      - ./src:/app/src
      - ./scripts:/app/scripts
      - ./models:/app/models
      - ./data:/app/data
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.0
    container_name: mlflow
    ports:
      - "5001:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://mlflow:mlflow@postgres-mlflow/mlflow
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=file:/mlflow/artifacts
    volumes:
      - mlflow-data:/mlflow
      - ./mlruns:/mlflow/mlruns
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri ${MLFLOW_BACKEND_STORE_URI} --default-artifact-root ${MLFLOW_DEFAULT_ARTIFACT_ROOT}
    depends_on:
      - postgres-mlflow
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL for MLflow
  postgres-mlflow:
    image: postgres:15
    container_name: postgres-mlflow
    environment:
      - POSTGRES_USER=mlflow
      - POSTGRES_PASSWORD=mlflow
      - POSTGRES_DB=mlflow
    volumes:
      - postgres-mlflow-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "mlflow"]
      interval: 5s
      retries: 5

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_ALERTING_ENABLED=true
      - GF_UNIFIED_ALERTING_ENABLED=true
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - grafana-alert-logs:/var/log/grafana
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIO - S3-compatible object storage for DVC
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

volumes:
  postgres-db-volume:
  postgres-mlflow-data:
  airflow-logs:
  prometheus-data:
  grafana-data:
  grafana-alert-logs:
  mlflow-data:
  minio-data:

